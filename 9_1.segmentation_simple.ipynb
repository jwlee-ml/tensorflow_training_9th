{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 1\n",
    "num_trainimgs = 234\n",
    "num_valimgs = 26\n",
    "decay_step = int(num_trainimgs / batch_size * 10)\n",
    "decay_rate = 0.9\n",
    "seed = 777\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "data_dir = cur_dir\n",
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')\n",
    "checkpoint_dir = os.path.join(cur_dir, 'checkpoints')\n",
    "TRAIN_FILE = 'train_images.tfrecords'\n",
    "VALIDATION_FILE = 'val_images.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tensor_shape(tensor, string):\n",
    "    print(string, tensor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(tfrecord_serialized):\n",
    "    features={'img_raw': tf.FixedLenFeature([], tf.string),\n",
    "             'label_raw': tf.FixedLenFeature([], tf.string)}\n",
    "    parsed_features = tf.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.decode_raw(parsed_features['img_raw'], tf.int64)\n",
    "    image.set_shape([65536])\n",
    "    image_re = tf.reshape(image, [256, 256])\n",
    "    image_re = tf.cast(image_re, tf.float32) * (1. / 1024)\n",
    "    label = tf.decode_raw(parsed_features['label_raw'], tf.uint8)\n",
    "    label.set_shape([65536])\n",
    "    label_re = tf.reshape(label, [256, 256])\n",
    "    #label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    #print(image_re.shape)\n",
    "    #print(label_re.shape)   \n",
    "    \n",
    "    return image_re, label_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(batch_size, tfrecord_path):    \n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.map(read_and_decode, num_parallel_calls=8)\n",
    "    dataset = dataset.shuffle(buffer_size=10000).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(images):\n",
    "    print_tensor_shape(images, 'input images shape')\n",
    "    images_re = tf.reshape(images, [-1, 256, 256, 1])\n",
    "    print_tensor_shape(images, 'input images shape after reshaping')\n",
    "    \n",
    "    # number of units in the hidden layer\n",
    "    hidden = 512\n",
    "    \n",
    "    with tf.name_scope('Hidden'):\n",
    "        w_fc1 = tf.Variable(tf.truncated_normal([256*256, hidden], stddev=0.1, dtype=tf.float32), name='w_fc1')\n",
    "        print_tensor_shape(w_fc1, 'w_fc1 shape')\n",
    "        \n",
    "        flatten_input = tf.reshape(images_re, [-1, 256*256])\n",
    "        print_tensor_shape(flatten_input, 'flattened input shape')\n",
    "        \n",
    "        net = tf.matmul(flatten_input, w_fc1)\n",
    "        print_tensor_shape(net, 'hidden layer shape')\n",
    "    \n",
    "    with tf.name_scope('Final'):\n",
    "        w_fc2 = tf.Variable(tf.truncated_normal([hidden, 256*256*2], stddev=0.1, dtype=tf.float32, name='w_fc2'))\n",
    "        print_tensor_shape(w_fc2, 'w_fc2 shape')\n",
    "        \n",
    "        net = tf.matmul(net, w_fc2)\n",
    "        print_tensor_shape(net, 'final layer shape')\n",
    "        \n",
    "        net = tf.reshape(net, [-1, 256, 256, 2])\n",
    "        print_tensor_shape(net, 'output shape')\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "    labels = tf.to_int64(labels)\n",
    "    print_tensor_shape(logits, 'logits shape before')\n",
    "    print_tensor_shape(labels, 'labels shape before')\n",
    "    \n",
    "    logits_re = tf.reshape(logits, [-1, 2])\n",
    "    labels_re = tf.reshape(labels, [-1])\n",
    "    print_tensor_shape(logits_re, 'logits shape after')\n",
    "    print_tensor_shape(labels_re, 'labels shale after')\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=labels, logits=logits, name='cross_entropy')\n",
    "    print_tensor_shape(cross_entropy, 'cross_entropy shape')\n",
    "    \n",
    "    loss = tf.reduce_mean(cross_entropy, name='simple_cross_entropy_mean')\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(loss, learning_rate, decay_steps, decay_rate):\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)    \n",
    "    lr = tf.train.exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(logits, labels):\n",
    "    with tf.name_scope('eval'):\n",
    "        labels = tf.to_int64(labels)\n",
    "        print_tensor_shape( logits, 'logits eval shape before')\n",
    "        print_tensor_shape( labels, 'labels eval shape before')\n",
    "\n",
    "        logits_re = tf.reshape( logits, [-1, 2] )\n",
    "        labels_re = tf.reshape( labels, [-1] )\n",
    "        print_tensor_shape( logits, 'logits eval shape after')\n",
    "        print_tensor_shape( labels, 'labels eval shape after')\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits_re, labels_re, 1)\n",
    "        print_tensor_shape( correct, 'correct shape')\n",
    "\n",
    "        return tf.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tfr_path = os.path.join(data_dir, TRAIN_FILE)\n",
    "val_tfr_path = os.path.join(data_dir, VALIDATION_FILE)\n",
    "\n",
    "train_dataset = make_dataset(batch_size, train_tfr_path)\n",
    "val_dataset = make_dataset(batch_size, val_tfr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "images, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_init = iterator.make_initializer(train_dataset)\n",
    "val_init = iterator.make_initializer(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = network(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = loss(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_op = training(loss, learning_rate, decay_step, decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_op = evaluation(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_prec_train = 0.\n",
    "    avg_prec_val = 0.\n",
    "    n_iter_train = int(num_trainimgs / batch_size)\n",
    "    n_iter_val = int(num_valimgs / batch_size)\n",
    "    \n",
    "    sess.run(train_init)    \n",
    "    for i in range(n_iter_train):\n",
    "        sess.run([images, labels])\n",
    "        _, loss_val = sess.run([train_op, loss])\n",
    "        prec = sess.run(eval_op)\n",
    "        avg_loss += loss_val / n_iter_train\n",
    "        avg_prec_train += prec / (n_iter_train * 256.0 * 256)\n",
    "    \n",
    "    sess.run(val_init)\n",
    "    for i in range(n_iter_val):\n",
    "        val_images, val_labels = sess.run([images, labels])\n",
    "        val_logits, prec = sess.run([logits, eval_op])\n",
    "        avg_prec_val += prec / (n_iter_val * 256.0 * 256)\n",
    "        '''if (epoch == num_epochs-1):            \n",
    "            val_images = np.reshape(val_images, (256, 256))\n",
    "            val_labels = np.reshape(val_labels, (256, 256))\n",
    "            val_logits = np.reshape(val_logits[:,:,:,1], (256, 256))\n",
    "            \n",
    "            plt.subplot(131)\n",
    "            plt.imshow(val_images, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.subplot(132)\n",
    "            plt.imshow(val_labels, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.subplot(133)\n",
    "            plt.imshow(val_logits, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.show()'''\n",
    "    \n",
    "    print('OUTPUT: epoch {}: loss = {:.5f}, train_precision = {:.3f}, val_precision = {:.3f}'.format(\n",
    "        epoch+1, avg_loss, avg_prec_train, avg_prec_val ))\n",
    "    saver.save(sess, checkpoint_path)\n",
    "print('Done Training for {} epochs'.format(num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
