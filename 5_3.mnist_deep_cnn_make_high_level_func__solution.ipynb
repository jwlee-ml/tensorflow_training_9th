{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    initial = tf.random_normal(shape, stddev=0.1)\n",
    "    #return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs, filters, kernel_size=[3,3], strides=[1,1], activation='Relu', padding='SAME'):\n",
    "    w_shape = kernel_size + [int(inputs.get_shape()[3])] + [filters]    \n",
    "    w = weight_variable(w_shape)    \n",
    "    strides = [1] + strides + [1]\n",
    "    layer = tf.nn.conv2d(inputs, w, strides=strides, padding=padding)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(inputs, pool_size=[2,2], strides=[2,2], padding='SAME'):\n",
    "    ksize = [1] + pool_size + [1]\n",
    "    strides = [1] + strides + [1]\n",
    "    return tf.nn.max_pool(inputs, ksize=ksize, strides=strides, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(inputs):\n",
    "    in_shape = inputs.get_shape()\n",
    "    return tf.reshape(inputs, [-1, int(in_shape[1]) * int(in_shape[2]) * int(in_shape[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense(inputs, units, activation='None'):\n",
    "    w_shape = [int(inputs.get_shape()[1]), units]    \n",
    "    w = weight_variable(w_shape)\n",
    "    b = bias_variable([units])\n",
    "    layer = tf.nn.bias_add(tf.matmul(inputs, w), b)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(inputs, rate=0.5, training=False):\n",
    "    keep_prob = 1. - rate\n",
    "    layer = tf.cond(training, lambda: tf.nn.dropout(inputs, keep_prob=keep_prob), lambda: inputs)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(tf.bool)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = conv2d(X_img, 32)\n",
    "pool1 = maxpool2d(conv1)\n",
    "drop1 = dropout(pool1, rate=0.3, training=is_train)\n",
    "#drop1 = tf.nn.dropout(pool1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2 = conv2d(drop1, 64)\n",
    "pool2 = maxpool2d(conv2)\n",
    "drop2 = dropout(pool2, rate=0.3, training=is_train)\n",
    "#drop2 = tf.nn.dropout(pool2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv3 = conv2d(drop2, 128)\n",
    "pool3 = maxpool2d(conv3)\n",
    "drop3 = dropout(pool3, rate=0.3, training=is_train)\n",
    "#drop3 = tf.nn.dropout(pool3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = flatten(drop3)\n",
    "dense4 = dense(flat3, 625, activation='Relu')\n",
    "drop4 = dropout(dense4, rate=0.5, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = dense(drop4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-09f9bfc0d396>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.734846356\n",
      "Epoch: 0002 cost = 0.171628803\n",
      "Epoch: 0003 cost = 0.120560721\n",
      "Epoch: 0004 cost = 0.093978759\n",
      "Epoch: 0005 cost = 0.078771980\n",
      "Epoch: 0006 cost = 0.069810547\n",
      "Epoch: 0007 cost = 0.062918831\n",
      "Epoch: 0008 cost = 0.058808743\n",
      "Epoch: 0009 cost = 0.052771744\n",
      "Epoch: 0010 cost = 0.047638798\n",
      "Epoch: 0011 cost = 0.044779395\n",
      "Epoch: 0012 cost = 0.042341923\n",
      "Epoch: 0013 cost = 0.041975970\n",
      "Epoch: 0014 cost = 0.037087197\n",
      "Epoch: 0015 cost = 0.036612126\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9937\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, is_train: False}))\n",
    "      #X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], is_train: False}))\n",
    "    #tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228a46ed710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
