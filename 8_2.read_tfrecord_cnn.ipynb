{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 64\n",
    "img_height = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrecord_train = 'train.tfrecord'\n",
    "tfrecord_test = 'test.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'\n",
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 20\n",
    "n_class = 20\n",
    "n_train = 800\n",
    "n_test = 200\n",
    "seed = 777\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_train)\n",
    "test_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.FixedLenFeature([], tf.string),\n",
    "             'label': tf.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    label = tf.cast(parsed_features['label'], tf.int32)\n",
    "    label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    print(image.shape)\n",
    "    print(label_onehot.shape)\n",
    "        \n",
    "    #image = tf.reshape(image, [-1, img_height, img_width, 3])\n",
    "    \n",
    "    return image, label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_tfr_path)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "#print(train_dataset.output_types, train_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset(test_tfr_path)\n",
    "test_dataset = test_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=10000).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "#print(test_dataset.output_types, test_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "image, label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_init = iterator.make_initializer(train_dataset)\n",
    "test_init = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = tf.reshape(image, [-1, img_height, img_width, 3])\n",
    "image = tf.cast(image, tf.float32) / 255.\n",
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=image, filters=32, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn1 = tf.layers.batch_normalization(pool1, training=is_train)\n",
    "#bn1 = tf.contrib.layers.batch_norm(pool1, decay=0.9, is_training=is_train)\n",
    "#drop1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=is_train)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=bn1, filters=64, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn2 = tf.layers.batch_normalization(pool2, training=is_train)\n",
    "#bn2 = tf.contrib.layers.batch_norm(pool2, decay=0.9, is_training=is_train)\n",
    "#drop2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=is_train)\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=bn2, filters=128, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn3 = tf.layers.batch_normalization(pool3, training=is_train)\n",
    "#bn3 = tf.contrib.layers.batch_norm(pool3, decay=0.9, is_training=is_train)\n",
    "#drop3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = tf.contrib.layers.flatten(bn3)\n",
    "dense4 = tf.layers.dense(inputs=flat3, units=625, activation=tf.nn.relu)\n",
    "bn4 = tf.layers.batch_normalization(dense4, training=is_train)\n",
    "#bn4 = tf.contrib.layers.batch_norm(dense4, decay=0.9, is_training=is_train)\n",
    "#drop4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_train)\n",
    "\n",
    "logits = tf.layers.dense(inputs=bn4, units=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=label))\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "max_test_acc = 0.\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    \n",
    "    total_batch = int(n_train / batch_size)\n",
    "    total_batch_test = int(n_test / batch_size)\n",
    "    \n",
    "    sess.run(train_init)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        #batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        #batch_xs = batch_xs.reshape(-1, time_steps, element_size)\n",
    "        sess.run([image, label])        \n",
    "        feed_dict = {is_train:True}\n",
    "        acc, c, _ = sess.run([accuracy, cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_train_acc += acc / total_batch\n",
    "        \n",
    "    sess.run(test_init)\n",
    "        \n",
    "    for i in range(total_batch_test):\n",
    "        #batch_xs, batch_ys = mnist.test.next_batch(batch_size)        \n",
    "        #batch_xs = batch_xs.reshape(-1, time_steps, element_size)\n",
    "        sess.run([image, label])\n",
    "        feed_dict = {is_train:False}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        avg_test_acc += acc / total_batch_test\n",
    "\n",
    "    print('Epoch:', '{}'.format(epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), \n",
    "          'train accuracy = ', '{:.5f}'.format(avg_train_acc), \n",
    "          'test accuracy = ', '{:.5f}'.format(avg_test_acc))\n",
    "\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
